{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cae51-ce6b-48a4-98d9-d025911c1005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80240f34-afa2-46d1-a7bf-07e54d707f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# MNE, spetral power functions, & FOOOF\n",
    "import mne\n",
    "from fooof import FOOOF\n",
    "from neurodsp.spectral import compute_spectrum\n",
    "\n",
    "# import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import wilcoxon, fisher_exact, chisquare\n",
    "\n",
    "# import local functions from iEEG_LKM library\n",
    "sys.path.append('/Users/christinamaher/Documents/Github/iEEG_LKM/preprocessing_utils.py')\n",
    "sys.path.append('/Users/christinamaher/Documents/Github/iEEG_LKM/stats_utils.py')\n",
    "from preprocessing_utils import join_clean_segments, load_label_file\n",
    "from stats_utils import assign_band, BOSC_tf, BOSC_detect, average_power, peak_count, average_duration\n",
    "\n",
    "# Initialize the directories\n",
    "data_dir = '/Users/christinamaher/Documents/projects/ieeg_lkm/data'\n",
    "results_dir = '/Users/christinamaher/Documents/projects/ieeg_lkm/results'\n",
    "\n",
    "subject_list = ['sub-01','sub-02','sub-03','sub-04','sub-05','sub-06','sub-07','sub-08'] # Define the subject list \n",
    "conditions = [\"baseline\",\"meditation\"] # Define the conditions\n",
    "regions = [\"amygdala\",\"hippocampus\"] # Regions \n",
    "sr = 250 # Define the sampling rate (250 Hz) for all recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c4557",
   "metadata": {},
   "source": [
    "# Preprocess iEEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba2a10",
   "metadata": {},
   "source": [
    "In the next cell, we will loop through each subject's data by condition. We will visually inspect the data and annotate noise/IED based on clinical criterion: [Mercier et al. (2022)](https://www.sciencedirect.com/science/article/pii/S1053811922005559) ; [Marcuse et al. (2015)](https://www.sciencedirect.com/book/9780323353878/rowans-primer-of-eeg). Clean data will be saved in .fif format for further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2099b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually inspect data for each recording (subject x condition) and annotate noisy timpoints\n",
    "for subject in subject_list:\n",
    "    for condition in conditions:\n",
    "        # Load the data\n",
    "        raw_data = mne.io.read_raw_fif(data_dir + '/' + subject + '_' + condition + '_raw.fif', preload=True, verbose=False) # Load the data\n",
    "        num_channels = raw_data.info['nchan'] # Get the number of channels\n",
    "        fig = raw_data.plot(start=2, duration=50, n_channels=num_channels,scalings=raw_data._data.max()* 10) # Plot the data (all channels, 50 seconds per window)\n",
    "        fig.fake_keypress(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated data to results directory \n",
    "for subject in subject_list:\n",
    "    for condition in conditions:\n",
    "        # save annotated data \n",
    "        raw_data.save(f'{results_dir}/{subject}_{condition}_annotated.fif', overwrite=True) # Save the annotated data for FOOOF and eBOSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop noisy timepoints from data and save clean data to results directory \n",
    "for subject in subject_list:\n",
    "    for condition in conditions:\n",
    "        # load the annotated data\n",
    "        annotated_data = mne.io.read_raw_fif(results_dir + '/' + subject + '_' + condition + '_annotated.fif', preload=True, verbose=False) \n",
    "        # concatenate good segments only \n",
    "        clean_data = join_clean_segments(annotated_data)\n",
    "        # save clean data\n",
    "        clean_data.save(f'{results_dir}/{subject}_{condition}_clean.fif', overwrite=True) # Save the cleaned data for FOOOF and eBOSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use chi-squared test to test whether the proportion of data retained following manual artifact rejection is significantly different than expected between conditions. \n",
    "baseline = []\n",
    "meditation = []\n",
    "\n",
    "for subject in subject_list:\n",
    "    baseline_data = mne.io.read_raw_fif(results_dir + '/' + subject + f'_{conditions[0]}_clean.fif', preload=True, verbose=False) # Load the data\n",
    "    baseline.append(baseline_data.n_times / (baseline_data.info['sfreq'] * 60))  # Get the proportion of clean data for the baseline condition (convert to minutes)\n",
    "    meditation_data = mne.io.read_raw_fif(results_dir + '/' + subject + f'_{conditions[1]}_clean.fif', preload=True, verbose=False) # Load the data\n",
    "    meditation.append(meditation_data.n_times / (meditation_data.info['sfreq'] * 60)) # Get the proportion of clean data for the meditation condition (convert to minutes)\n",
    "\n",
    "\n",
    "observed_counts = np.array([np.sum(baseline), np.sum(meditation)]) # Calculate the mean proportion of clean data for each condition\n",
    "expected_counts = np.array([np.sum(observed_counts)/2, np.sum(observed_counts)/2]) # Calculate the expected counts (assuming 50-50 distribution of clean data between conditions)\n",
    "\n",
    "# Perform the chi-squared test\n",
    "print(observed_counts, expected_counts)\n",
    "chi2_stat, p = chisquare(f_obs=observed_counts, f_exp=expected_counts)\n",
    "\n",
    "# Print results\n",
    "print(f\"Observed counts: {observed_counts}\")\n",
    "print(f\"Expected counts: {expected_counts}\")\n",
    "print(f\"Chi-squared test: stat = {chi2_stat:.2f}, p = {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000eef7",
   "metadata": {},
   "source": [
    "# FOOOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7cafa",
   "metadata": {},
   "source": [
    "In the following cell, we will loop through all patients by condition and perform [FOOOF model fit](https://github.com/fooof-tools/fooof). Results (aperiodic and periodic features of the power spectra for each channel x condition) will be saved to a csv file to perform statistics and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a92eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the aperiodic and periodic parameters for each channel \n",
    "aperiodic_df = []\n",
    "periodic_df = []\n",
    "\n",
    "# Intialize FOOOF object\n",
    "freq_range = [2, 55]\n",
    "fm = FOOOF(aperiodic_mode='knee',peak_width_limits=[1, 8]) # hyperparameter setting\n",
    "\n",
    "# Define bands dictionary to assign canonical frequency bands (str) to each frequency (Hz). \n",
    "bands = {\n",
    "    'delta': (2, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 55)\n",
    "}\n",
    "\n",
    "for subject in subject_list: # Loop through each subject\n",
    "    baseline_data = mne.io.read_raw_fif(f'{data_dir}/{subject}_baseline_clean.fif') # Load the baseline data\n",
    "    meditation_data = mne.io.read_raw_fif(f'{data_dir}/{subject}_meditation_clean.fif') # Load the meditation data\n",
    "    num_channels = len(baseline_data.ch_names) # Get the number of channels in the data (this will be used to loop through each channel)\n",
    "    sr = baseline_data.info['sfreq'] # sampling rate (250 Hz)\n",
    "\n",
    "    for channel in range(num_channels): # Loop through each channel\n",
    "        for condition in conditions: # Loop through each condition (baseline and meditation)\n",
    "            data = globals()[f\"{condition}_data\"].get_data()[channel, :] # Get the data for the channel and condition\n",
    "            freq_mean, psd_mean = compute_spectrum(data, sr, method='welch',nperseg=sr*2) # Compute the power spectrum for the data using Welch's method\n",
    "            fm.report(freq_mean, psd_mean, freq_range) # Fit the power spectrum with the FOOOF model\n",
    "            ap_params, peak_params, _, _, _ = fm.get_results() # Get the aperiodic and periodic parameters from the FOOOF model\n",
    "\n",
    "            # Store the aperiodic/periodic parameters in a dataframe\n",
    "            ap_params = ap_params.tolist() + [channel] + [condition] + [subject] # Add the channel number, condition, and subject info to the aperiodic parameters\n",
    "            ap_params = np.reshape(ap_params, (1,6))\n",
    "            columns = ['offset','knee','exponent', 'electrode','condition', 'subject'] # Define the columns for the aperiodic dataframe\n",
    "            ap_df = pd.DataFrame(ap_params, columns=columns) # Create a dataframe from the aperiodic parameters\n",
    "            aperiodic_df.append(ap_df) # Append the aperiodic dataframe to the list of aperiodic dataframes\n",
    "\n",
    "            pp_df = pd.DataFrame(peak_params) # Create a dataframe from the periodic parameters\n",
    "            pp_df['electrode'] = channel # Add the channel number to the peak_params dataframe\n",
    "            pp_df = pp_df.rename(columns={0: 'center_frequency', 1: 'power', 2: 'bandwidth', 'electrode': 'elec'}) # Rename the columns of the peak_params dataframe\n",
    "            pp_df['condition'] = condition # Add the condition to the peak_params dataframe\n",
    "            pp_df['subject'] = subject # Add the subject to the peak_params dataframe\n",
    "            periodic_df.append(pp_df) # Append the periodic dataframe to the list of periodic dataframes\n",
    "\n",
    "# Concatenate the aperiodic and periodic dataframes\n",
    "aperiodic_df = pd.concat(aperiodic_df) # Concatenate the list of aperiodic dataframes\n",
    "periodic_df = pd.concat(periodic_df) # Concatenate the list of periodic dataframes\n",
    "\n",
    "# Assign frequency bands to the center frequency of each peak\n",
    "periodic_df['Freq_Band'] = periodic_df['center_frequency'].apply(assign_band,bands=bands)\n",
    "\n",
    "# Save the aperiodic and periodic dataframes to a csv file\n",
    "aperiodic_df.to_csv(f'{results_dir}/aperiodic_results.csv', index=False) \n",
    "periodic_df.to_csv(f'{results_dir}/periodic_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b258622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average power and number of peaks in each frequency band for each channel and condition using average_power() and peak_count() from stats_utils\n",
    "\n",
    "# Group by unique combinations of electrode, subject, and condition\n",
    "grouped = periodic_df.groupby(['elec', 'subject','condition'])\n",
    "\n",
    "# Initialize an empty dictionary to store the results\n",
    "avg_power_by_band = {}\n",
    "num_peaks_by_band = {}\n",
    "\n",
    "# Iterate over each group\n",
    "for (elec, subject, condition), group_df in grouped:\n",
    "    # Apply the average_power function to the group\n",
    "    avg_power_by_band[(elec, subject, condition)] = average_power(group_df)\n",
    "    num_peaks_by_band[(elec, subject, condition)] = peak_count(group_df,bands)\n",
    "    \n",
    "# Convert dictionary to DF\n",
    "peaks_df = pd.DataFrame.from_dict(num_peaks_by_band, orient='index')\n",
    "power_df = pd.DataFrame.from_dict(avg_power_by_band, orient='index')\n",
    "\n",
    "# Reset index and rename columns\n",
    "peaks_df.reset_index(inplace=True)\n",
    "peaks_df.rename(columns={'level_0': 'electrode', 'level_1': 'subject', 'level_2': 'condition'}, inplace=True)\n",
    "peaks_df = pd.melt(peaks_df, id_vars=['electrode', 'subject', 'condition'], var_name='freq_band', value_name='peak')\n",
    "\n",
    "power_df.reset_index(inplace=True)\n",
    "power_df.rename(columns={'level_0': 'electrode', 'level_1': 'subject', 'level_2': 'condition'}, inplace=True)\n",
    "power_df = pd.melt(power_df, id_vars=['electrode', 'subject', 'condition'], var_name='freq_band', value_name='power')\n",
    "\n",
    "\n",
    "# Add anatomical localization information to results dataframes \n",
    "\n",
    "# Loop through each subject\n",
    "for subject in subject_list:\n",
    "    # Load label file for the current subject\n",
    "    label_df = load_label_file(subject)\n",
    "    \n",
    "    # If label file exists\n",
    "    if label_df is not None:\n",
    "        # Merge anatomical localization information with power and peak dataframes\n",
    "        power_df_subject = power_df[power_df['subject'] == subject]\n",
    "        peaks_df_subject = peaks_df[peaks_df['subject'] == subject]\n",
    "        \n",
    "        power_df_subject = pd.merge(power_df_subject, label_df, how='left', on='electrode')\n",
    "        peaks_df_subject = pd.merge(peaks_df_subject, label_df, how='left', on='electrode')\n",
    "        \n",
    "        # Append merged dataframes to the list\n",
    "        all_power_dfs.append(power_df_subject)\n",
    "        all_peaks_dfs.append(peaks_df_subject)\n",
    "\n",
    "# Concatenate dataframes for all subjects\n",
    "all_power_df = pd.concat(all_power_dfs, ignore_index=True)\n",
    "all_peaks_df = pd.concat(all_peaks_dfs, ignore_index=True)\n",
    "\n",
    "# Save results to a csv file \n",
    "power_df.to_csv(f'{results_dir}/power_df.csv', index=False)\n",
    "peaks_df.to_csv(f'{results_dir}/peaks_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use wilcoxon signed-rank test to compare the average power in each frequency band between conditions. Based on literature and hypotheses, tests for gamma band are one-tailed, while tests for other bands are two-tailed.\n",
    "\n",
    "for region in regions:\n",
    "    for band in bands.keys(): # Loop through each frequency band\n",
    "        baseline_power = power_df.query(f\"condition == 'baseline' & freq_band == '{band}' & region == '{region}'\")['power'] # Get power in the baseline condition for the band\n",
    "        meditation_power = power_df.query(f\"condition == 'meditation' & freq_band == '{band}' & region == '{region}'\")['power'] # Get power in the meditation condition for the band\n",
    "\n",
    "        # Filter out rows with null values in either baseline or meditation power\n",
    "        valid_indices = ~(baseline_power.isnull() | meditation_power.isnull())\n",
    "        baseline_power = baseline_power[valid_indices]\n",
    "        meditation_power = meditation_power[valid_indices]\n",
    "\n",
    "        if band == 'gamma': # Check if the band is gamma\n",
    "            stat, p = wilcoxon(baseline_power, meditation_power, alternative='greater') # Perform the Wilcoxon signed-rank test with a one-tailed test\n",
    "        else: # If the band is not gamma\n",
    "            stat, p = wilcoxon(baseline_power, meditation_power) # Perform the Wilcoxon signed-rank test with a two-tailed test\n",
    "        print(f\"{region} {band}: stat = {stat}, p = {p}\") # Print the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3055a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate proportion of peaks by band, region, and condition\n",
    "prop_peaks_by_band = peaks_df.groupby(['condition', 'freq_band','region'])['peak'].mean().reset_index()\n",
    "\n",
    "# Use Fisher's exact test to compare the proportion of peaks detected in each frequency band between conditions\n",
    "\n",
    "# Group the data by frequency band and region\n",
    "grouped_data = prop_peaks_by_band.groupby(['freq_band','region'])\n",
    "\n",
    "# Perform Fisher's exact test for each frequency band and region combination\n",
    "for (freq_band,region), freq_band_region_data in grouped_data:\n",
    "    contingency_table = [[freq_band_region_data[(freq_band_region_data['condition'] == 'baseline')]['peak'].sum(), freq_band_region_data[(freq_band_region_data['condition'] == 'meditation')]['peak'].sum()],\n",
    "                         [len(freq_band_region_data[(freq_band_region_data['condition'] == 'baseline')]) - freq_band_region_data[(freq_band_region_data['condition'] == 'baseline')]['peak'].sum(),\n",
    "                          len(freq_band_region_data[(freq_band_region_data['condition'] == 'meditation')]) - freq_band_region_data[(freq_band_region_data['condition'] == 'meditation')]['peak'].sum()]]\n",
    "\n",
    "    oddsratio, p = fisher_exact(contingency_table)\n",
    "    print(f\"Fisher's exact test for {freq_band} in {region}: p-value = {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c348bf3-527a-4cbc-8ca9-035e9d9358cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# eBOSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e006d49",
   "metadata": {},
   "source": [
    "In the following cell, we will loop through all patients by condition and perform [eBOSC model fit](https://github.com/jkosciessa/eBOSC_py). Results (proportion of time spent oscillating at each frequency for each channel x condition) will be saved to a csv file to perform statistics and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb665da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] # Initialize a list to store the results (one dataframe per channel: columns are frequency (int), frequency band (str), proportion of time spent oscillating (int), channel (str), participant (str), and condition (str))\n",
    "\n",
    "for subject in subject_list: # Loop through each subject\n",
    "\n",
    "    baseline_data = mne.io.read_raw_fif(f'{data_dir}/{subject}_baseline_clean.fif') # Load the baseline data\n",
    "    meditation_data = mne.io.read_raw_fif(f'{data_dir}/{subject}_meditation_clean.fif') # Load the meditation data\n",
    "    num_channels = len(baseline_data.ch_names) # Get the number of channels in the data (this will be used to loop through each channel)\n",
    "    sr = baseline_data.info['sfreq'] # Sampling rate - this is the same for both baseline and meditation data (250 Hz for these NeuroPace data).\n",
    "\n",
    "    for channel in range(num_channels): # Loop through each channel\n",
    "        for condition in conditions: # Loop through each condition (baseline and meditation)\n",
    "            data = globals()[f\"{condition}_data\"].get_data()[channel, :] # Get the data for the channel and condition\n",
    "            f = np.linspace(1, 55, 44) # Frequency range - this is the same for both baseline and meditation data (1-55 Hz). \n",
    "            wavelet = 4 # the wavenumber to use for the Morlet wavelet\n",
    "            B, T, F = BOSC_tf(data, f, sr, wavelet) # Compute the BOSC time-frequency matrix for a given LFP signal.\n",
    "            exog = np.log10(F) # Log transform the frequency values\n",
    "            exog = sm.add_constant(exog) # Add a constant to the exogenous variable\n",
    "            endog = np.log10(B).mean(axis=-1) # Log transform the BOSC values and take the mean across time\n",
    "            rlm_model = sm.RLM(endog, exog, M=sm.robust.norms.TukeyBiweight()) # Create a robust linear model which is used to fit the data because it is less sensitive to outliers than OLS regression. \n",
    "            rlm_results = rlm_model.fit() # Fit the model\n",
    "            pv = np.zeros(2) # Initialize the parameter vector\n",
    "            pv[0] = rlm_results.params[1] # Assign the slope to the first element of the parameter vector\n",
    "            pv[1] = rlm_results.params[0] # Assign the intercept to the second element of the parameter vector\n",
    "            mp = 10**(np.polyval(pv,np.log10(F))) # Compute the model fit\n",
    "            pt=chi2.ppf(0.95,2)*mp/2 # Compute the power threshold (95% confidence interval for the model fit)\n",
    "            dt=(3*sr/F) # Compute the duration threshold (3 cycles of the given frequency)\n",
    "            detected = np.zeros_like(B) # Initialize the detected array\n",
    "            for freq_ix in range(len(F)): # Loop through each frequency\n",
    "                detected[freq_ix, :] = BOSC_detect(B[freq_ix,:], # Detect oscillations based on the power timecourse as a given frequency using pre-defined power and duration thresholds\n",
    "                                                powthresh=pt[freq_ix], # Power threshold\n",
    "                                                durthresh=dt[freq_ix], # Duration threshold\n",
    "                                                Fsample=sr) # Sampling rate\n",
    "            time_spent_oscillating = detected.sum(axis=-1) # Compute the time spent oscillating\n",
    "            total_time = len(T) # Compute the total time\n",
    "            proportion_time_oscillating = time_spent_oscillating/total_time # Compute the proportion of time spent oscillating (time spent oscillating/total time)\n",
    "            temp_df = pd.DataFrame({'Freq': F, 'Prop_Time': proportion_time_oscillating, 'Channel':channel, 'Participant':subject,'Condition':condition}) # Create a temporary dataframe to store the results from the current channel and condition\n",
    "            results.append(temp_df) # Append the temporary dataframe to the results list\n",
    "        \n",
    "results = pd.concat(results,ignore_index=True) # Concatenate the results list into a single dataframe\n",
    "\n",
    "\n",
    "# Assign frequency bands to the frequencies\n",
    "results['Freq_Band'] = results['Freq'].apply(assign_band, bands=bands) # Apply the function to the 'Freq' column to create a new column 'FrequencyBand' that assigns the canonical frequency band based on the frequency. \n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "results.to_csv(f'{results_dir}/ebosc_results.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the average proportion of time spent oscillating in each frequency band for each channel and condition using average_duration() from stats_utils\n",
    "avg_duration_by_band = average_duration(results)\n",
    "\n",
    "# Save results to a csv file \n",
    "avg_duration_by_band.to_csv(f'{results_dir}/avg_duration_by_band.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdc142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use wilcoxon signed-rank test to compare the average proportion of time spent oscillating in each frequency band between conditions. Based on literature and hypotheses, tests for beta band are one-tailed, while tests for other bands are two-tailed.\n",
    "for region in regions:\n",
    "    for band in bands.keys(): # Loop through each frequency band\n",
    "        baseline_duration = avg_duration_by_band.query(f\"condition == 'baseline' & band == '{band}' & region == '{region}'\")['duration'] # Get the average duration in the baseline condition for the band\n",
    "        meditation_duration = avg_duration_by_band.query(f\"condition == 'meditation' & band == '{band}' & region == '{region}'\")['duration'] # Get the average duration in the meditation condition for the band\n",
    "        if band == 'beta':\n",
    "            stat, p = wilcoxon(baseline_duration, meditation_duration, alternative='greater') # Perform the Wilcoxon signed-rank test with a one-tailed test\n",
    "        else:\n",
    "            stat, p = wilcoxon(baseline_duration, meditation_duration) # Perform the Wilcoxon signed-rank test with a two-tailed test\n",
    "\n",
    "        print(f\"{region} {band}: stat = {stat}, p = {p}\") # Print the p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ca3c2",
   "metadata": {},
   "source": [
    "# Supplemental analyses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare aperiodic parameters between regions (amygdala and hippocampus) at baseline\n",
    "\n",
    "# Load the aperiodic results\n",
    "aperiodic_df = pd.read_csv(f'results_dir/aperiodic_results.csv')\n",
    "\n",
    "# Filter the aperiodic results to only include the amygdala and hippocampus\n",
    "amygdala = aperiodic_df.query(\"region == 'amygdala'\") # Filter the aperiodic results to only include the amygdala\n",
    "hippocampus = aperiodic_df.query(\"region == 'hippocampus'\") # Filter the aperiodic results to only include the hippocampus\n",
    "\n",
    "# Perform a wilcoxon signed-rank test to compare the aperiodic parameters between the amygdala and hippocampus at baseline\n",
    "\n",
    "for param in ['offset','knee','exponent']: # Loop through each aperiodic parameter\n",
    "    amygdala_param = amygdala.query(\"condition == 'baseline'\")[param] # Get the aperiodic parameter for the amygdala at baseline\n",
    "    hippocampus_param = hippocampus.query(\"condition == 'baseline'\")[param] # Get the aperiodic parameter for the hippocampus at baseline\n",
    "    stat, p = wilcoxon(amygdala_param, hippocampus_param) # Perform the Wilcoxon signed-rank test\n",
    "    print(f\"{param}: stat = {stat}, p = {p}\") # Print the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare periodic parameters (power, duration) between regions (amygdala and hippocampus) at baseline\n",
    "\n",
    "# Load the average power by band results\n",
    "power_df = pd.read_csv(f'results_dir/avg_power_by_band.csv')\n",
    "power_df['periodic_feature'] = 'power' \n",
    "duration_df = pd.read_csv(f'results_dir/avg_duration_by_band.csv')\n",
    "duration_df['periodic_feature'] = 'duration'\n",
    "\n",
    "# Combine the power and duration dataframes\n",
    "periodic_df = pd.merge(power_df, duration_df, on=['electrode','condition','subject','band']) # Merge the power and duration dataframes\n",
    "\n",
    "# Filter the periodic results to only include the amygdala and hippocampus\n",
    "amygdala = periodic_df.query(\"region == 'amygdala'\") # Filter the periodic results to only include the amygdala\n",
    "hippocampus = periodic_df.query(\"region == 'hippocampus'\") # Filter the periodic results to only include the hippocampus\n",
    "\n",
    "# Perform a wilcoxon signed-rank test to compare the periodic parameters between the amygdala and hippocampus at baseline\n",
    "\n",
    "for param in ['power','duration']: # Loop through each periodic parameter\n",
    "    amygdala_param = amygdala.query(\"condition == 'baseline'\")[param] # Get the periodic parameter for the amygdala at baseline\n",
    "    hippocampus_param = hippocampus.query(\"condition == 'baseline'\")[param] # Get the periodic parameter for the hippocampus at baseline\n",
    "    stat, p = wilcoxon(amygdala_param, hippocampus_param) # Perform the Wilcoxon signed-rank test\n",
    "    print(f\"{param}: stat = {stat}, p = {p}\") # Print the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a303ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the magnitude of condition-related changes (meditation - baseline) in periodic parameter (power, duration) between regions (amygdala and hippocampus)\n",
    "\n",
    "# Compute the change in periodic parameters between conditions\n",
    "periodic_df['change'] = periodic_df['meditation'] - periodic_df['baseline']\n",
    "\n",
    "# Filter the periodic results to only include the amygdala and hippocampus\n",
    "amygdala = periodic_df.query(\"region == 'amygdala'\") # Filter the periodic results to only include the amygdala\n",
    "hippocampus = periodic_df.query(\"region == 'hippocampus'\") # Filter the periodic results to only include the hippocampus\n",
    "\n",
    "# Perform a wilcoxon signed-rank test to compare the change in periodic parameters between the amygdala and hippocampus\n",
    "\n",
    "for param in ['power','duration']: # Loop through each periodic parameter\n",
    "    amygdala_param = amygdala.query(\"condition == 'baseline'\")[param] # Get the change in the periodic parameter for the amygdala\n",
    "    hippocampus_param = hippocampus.query(\"condition == 'baseline'\")[param] # Get the change in the periodic parameter for the hippocampus\n",
    "    stat, p = wilcoxon(amygdala_param, hippocampus_param) # Perform the Wilcoxon signed-rank test\n",
    "    print(f\"{param}: stat = {stat}, p = {p}\") # Print the p-value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
